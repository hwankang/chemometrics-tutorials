{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL4hlHb1/NQSO1EzVCC5j5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/chemometrics-tutorials/blob/master/05(mon)_Dec__10_14_pm_R2_0_445(stacking)_Adaboost_negative_Gradient_Boost_negative_NIR_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XEtLrSaws01",
        "outputId": "bfb9595a-457f-4df7-d7d2-d8d10c833f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename='/content/drive/MyDrive/machine_learning/123_Raman_DATA_csv.csv'\n",
        "filename_a='/content/drive/MyDrive/machine_learning/A_NIR_DATA_csv.csv'\n",
        "import pandas as pd\n",
        "data_a = pd.read_csv(filename_a,header=0, \n",
        "                   encoding=\"unicode-escape\")"
      ],
      "metadata": {
        "id": "WeXe7TVuw6rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx,yy=data_a.shape\n",
        "xx"
      ],
      "metadata": {
        "id": "I015htzuxA8f",
        "outputId": "5b218b71-00bc-4c7e-af95-b52deef6bada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2039"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a2=data_a.iloc[0::,1:yy+1]\n",
        "data_a2.head()"
      ],
      "metadata": {
        "id": "9kyyE75qxvRj",
        "outputId": "a40a95ef-9845-4199-f019-0b787761a333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ¸ðµ¨ Æ÷ÇÔ   Y_A  899.9280058  900.2520706  900.5763689  900.9009009  \\\n",
              "0       True  24.0     0.098681     0.100515     0.102056     0.100267   \n",
              "1       True  24.0     0.098081     0.099926     0.101394     0.099664   \n",
              "2       True  24.0     0.089885     0.092072     0.094055     0.092618   \n",
              "3       True  23.6     0.088701     0.090287     0.091825     0.090534   \n",
              "4       True  23.6     0.095273     0.096945     0.098684     0.097460   \n",
              "\n",
              "   901.2256669  901.5506671  901.8759019  902.2013713  ...  2477.700694  \\\n",
              "0     0.096954     0.096161     0.097151     0.096790  ...     2.968741   \n",
              "1     0.096598     0.095915     0.096567     0.095609  ...     2.960005   \n",
              "2     0.089560     0.088900     0.089790     0.089088  ...     2.943931   \n",
              "3     0.087883     0.087348     0.088151     0.087593  ...     2.935452   \n",
              "4     0.094674     0.093949     0.094563     0.093743  ...     2.966199   \n",
              "\n",
              "   2480.15873  2482.621648  2485.089463  2487.562189  2490.039841  \\\n",
              "0    2.968988     2.958685     2.950201     2.950122     2.948725   \n",
              "1    2.959948     2.951504     2.945633     2.947553     2.947326   \n",
              "2    2.943679     2.930295     2.919846     2.920668     2.922776   \n",
              "3    2.938259     2.928736     2.921757     2.924166     2.924666   \n",
              "4    2.968021     2.955198     2.942411     2.943006     2.942151   \n",
              "\n",
              "   2492.522433  2495.00998  2497.502498      2500  \n",
              "0     2.939113    2.929406     2.929555  2.927579  \n",
              "1     2.937901    2.926926     2.924102  2.920722  \n",
              "2     2.913596    2.904503     2.903535  2.901086  \n",
              "3     2.914831    2.905151     2.902643  2.897351  \n",
              "4     2.931640    2.918549     2.918717  2.917849  \n",
              "\n",
              "[5 rows x 1781 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58427b7d-3d28-4c9e-a6e8-776f2f4ea6a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>¸ðµ¨ Æ÷ÇÔ</th>\n",
              "      <th>Y_A</th>\n",
              "      <th>899.9280058</th>\n",
              "      <th>900.2520706</th>\n",
              "      <th>900.5763689</th>\n",
              "      <th>900.9009009</th>\n",
              "      <th>901.2256669</th>\n",
              "      <th>901.5506671</th>\n",
              "      <th>901.8759019</th>\n",
              "      <th>902.2013713</th>\n",
              "      <th>...</th>\n",
              "      <th>2477.700694</th>\n",
              "      <th>2480.15873</th>\n",
              "      <th>2482.621648</th>\n",
              "      <th>2485.089463</th>\n",
              "      <th>2487.562189</th>\n",
              "      <th>2490.039841</th>\n",
              "      <th>2492.522433</th>\n",
              "      <th>2495.00998</th>\n",
              "      <th>2497.502498</th>\n",
              "      <th>2500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.098681</td>\n",
              "      <td>0.100515</td>\n",
              "      <td>0.102056</td>\n",
              "      <td>0.100267</td>\n",
              "      <td>0.096954</td>\n",
              "      <td>0.096161</td>\n",
              "      <td>0.097151</td>\n",
              "      <td>0.096790</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968741</td>\n",
              "      <td>2.968988</td>\n",
              "      <td>2.958685</td>\n",
              "      <td>2.950201</td>\n",
              "      <td>2.950122</td>\n",
              "      <td>2.948725</td>\n",
              "      <td>2.939113</td>\n",
              "      <td>2.929406</td>\n",
              "      <td>2.929555</td>\n",
              "      <td>2.927579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.098081</td>\n",
              "      <td>0.099926</td>\n",
              "      <td>0.101394</td>\n",
              "      <td>0.099664</td>\n",
              "      <td>0.096598</td>\n",
              "      <td>0.095915</td>\n",
              "      <td>0.096567</td>\n",
              "      <td>0.095609</td>\n",
              "      <td>...</td>\n",
              "      <td>2.960005</td>\n",
              "      <td>2.959948</td>\n",
              "      <td>2.951504</td>\n",
              "      <td>2.945633</td>\n",
              "      <td>2.947553</td>\n",
              "      <td>2.947326</td>\n",
              "      <td>2.937901</td>\n",
              "      <td>2.926926</td>\n",
              "      <td>2.924102</td>\n",
              "      <td>2.920722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.089885</td>\n",
              "      <td>0.092072</td>\n",
              "      <td>0.094055</td>\n",
              "      <td>0.092618</td>\n",
              "      <td>0.089560</td>\n",
              "      <td>0.088900</td>\n",
              "      <td>0.089790</td>\n",
              "      <td>0.089088</td>\n",
              "      <td>...</td>\n",
              "      <td>2.943931</td>\n",
              "      <td>2.943679</td>\n",
              "      <td>2.930295</td>\n",
              "      <td>2.919846</td>\n",
              "      <td>2.920668</td>\n",
              "      <td>2.922776</td>\n",
              "      <td>2.913596</td>\n",
              "      <td>2.904503</td>\n",
              "      <td>2.903535</td>\n",
              "      <td>2.901086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>23.6</td>\n",
              "      <td>0.088701</td>\n",
              "      <td>0.090287</td>\n",
              "      <td>0.091825</td>\n",
              "      <td>0.090534</td>\n",
              "      <td>0.087883</td>\n",
              "      <td>0.087348</td>\n",
              "      <td>0.088151</td>\n",
              "      <td>0.087593</td>\n",
              "      <td>...</td>\n",
              "      <td>2.935452</td>\n",
              "      <td>2.938259</td>\n",
              "      <td>2.928736</td>\n",
              "      <td>2.921757</td>\n",
              "      <td>2.924166</td>\n",
              "      <td>2.924666</td>\n",
              "      <td>2.914831</td>\n",
              "      <td>2.905151</td>\n",
              "      <td>2.902643</td>\n",
              "      <td>2.897351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>23.6</td>\n",
              "      <td>0.095273</td>\n",
              "      <td>0.096945</td>\n",
              "      <td>0.098684</td>\n",
              "      <td>0.097460</td>\n",
              "      <td>0.094674</td>\n",
              "      <td>0.093949</td>\n",
              "      <td>0.094563</td>\n",
              "      <td>0.093743</td>\n",
              "      <td>...</td>\n",
              "      <td>2.966199</td>\n",
              "      <td>2.968021</td>\n",
              "      <td>2.955198</td>\n",
              "      <td>2.942411</td>\n",
              "      <td>2.943006</td>\n",
              "      <td>2.942151</td>\n",
              "      <td>2.931640</td>\n",
              "      <td>2.918549</td>\n",
              "      <td>2.918717</td>\n",
              "      <td>2.917849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1781 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58427b7d-3d28-4c9e-a6e8-776f2f4ea6a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58427b7d-3d28-4c9e-a6e8-776f2f4ea6a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58427b7d-3d28-4c9e-a6e8-776f2f4ea6a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a2.iloc[4,0]"
      ],
      "metadata": {
        "id": "SNiQgUlFqnqm",
        "outputId": "595a5a37-c51d-419e-df56-b9f3ab69eca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai=[]\n",
        "for i in range(xx):\n",
        "    if data_a2.iloc[i,0]==False:\n",
        "        ai.append(i)\n",
        "data_a3=data_a2.drop(ai,axis=0) #\n",
        "data_a3\n",
        "len(ai)\n",
        "data_a3"
      ],
      "metadata": {
        "id": "RstzoQrFpxIm",
        "outputId": "77171d1d-4d92-4849-904a-c3e3ab2d84f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ¸ðµ¨ Æ÷ÇÔ    Y_A  899.9280058  900.2520706  900.5763689  900.9009009  \\\n",
              "0          True  24.00     0.098681     0.100515     0.102056     0.100267   \n",
              "1          True  24.00     0.098081     0.099926     0.101394     0.099664   \n",
              "2          True  24.00     0.089885     0.092072     0.094055     0.092618   \n",
              "3          True  23.60     0.088701     0.090287     0.091825     0.090534   \n",
              "4          True  23.60     0.095273     0.096945     0.098684     0.097460   \n",
              "...         ...    ...          ...          ...          ...          ...   \n",
              "2034       True  25.52     0.076506     0.075591     0.074629     0.072980   \n",
              "2035       True  25.52     0.071916     0.071201     0.070450     0.068871   \n",
              "2036       True  25.37     0.055557     0.054680     0.053789     0.052091   \n",
              "2037       True  25.37     0.050590     0.049846     0.049057     0.047327   \n",
              "2038       True  25.37     0.063837     0.062890     0.062142     0.060671   \n",
              "\n",
              "      901.2256669  901.5506671  901.8759019  902.2013713  ...  2477.700694  \\\n",
              "0        0.096954     0.096161     0.097151     0.096790  ...     2.968741   \n",
              "1        0.096598     0.095915     0.096567     0.095609  ...     2.960005   \n",
              "2        0.089560     0.088900     0.089790     0.089088  ...     2.943931   \n",
              "3        0.087883     0.087348     0.088151     0.087593  ...     2.935452   \n",
              "4        0.094674     0.093949     0.094563     0.093743  ...     2.966199   \n",
              "...           ...          ...          ...          ...  ...          ...   \n",
              "2034     0.072275     0.072979     0.072688     0.070171  ...     2.962918   \n",
              "2035     0.068104     0.068746     0.068455     0.065891  ...     2.982798   \n",
              "2036     0.051338     0.052176     0.052068     0.049510  ...     2.960384   \n",
              "2037     0.046489     0.047292     0.047258     0.044905  ...     2.968252   \n",
              "2038     0.060073     0.060987     0.060884     0.058203  ...     2.981493   \n",
              "\n",
              "      2480.15873  2482.621648  2485.089463  2487.562189  2490.039841  \\\n",
              "0       2.968988     2.958685     2.950201     2.950122     2.948725   \n",
              "1       2.959948     2.951504     2.945633     2.947553     2.947326   \n",
              "2       2.943679     2.930295     2.919846     2.920668     2.922776   \n",
              "3       2.938259     2.928736     2.921757     2.924166     2.924666   \n",
              "4       2.968021     2.955198     2.942411     2.943006     2.942151   \n",
              "...          ...          ...          ...          ...          ...   \n",
              "2034    2.970997     2.967865     2.957785     2.952054     2.949278   \n",
              "2035    2.982529     2.968697     2.958179     2.962882     2.967330   \n",
              "2036    2.958313     2.946722     2.938467     2.936874     2.936340   \n",
              "2037    2.967836     2.953877     2.942397     2.945923     2.948910   \n",
              "2038    2.981399     2.970350     2.962294     2.963960     2.962348   \n",
              "\n",
              "      2492.522433  2495.00998  2497.502498      2500  \n",
              "0        2.939113    2.929406     2.929555  2.927579  \n",
              "1        2.937901    2.926926     2.924102  2.920722  \n",
              "2        2.913596    2.904503     2.903535  2.901086  \n",
              "3        2.914831    2.905151     2.902643  2.897351  \n",
              "4        2.931640    2.918549     2.918717  2.917849  \n",
              "...           ...         ...          ...       ...  \n",
              "2034     2.941087    2.935639     2.936698  2.938116  \n",
              "2035     2.958188    2.948901     2.948394  2.943151  \n",
              "2036     2.925951    2.920350     2.921682  2.917657  \n",
              "2037     2.940729    2.926084     2.923839  2.919868  \n",
              "2038     2.953168    2.948091     2.949026  2.943110  \n",
              "\n",
              "[1823 rows x 1781 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72d5a398-0dca-4075-a73b-7e60d12c16f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>¸ðµ¨ Æ÷ÇÔ</th>\n",
              "      <th>Y_A</th>\n",
              "      <th>899.9280058</th>\n",
              "      <th>900.2520706</th>\n",
              "      <th>900.5763689</th>\n",
              "      <th>900.9009009</th>\n",
              "      <th>901.2256669</th>\n",
              "      <th>901.5506671</th>\n",
              "      <th>901.8759019</th>\n",
              "      <th>902.2013713</th>\n",
              "      <th>...</th>\n",
              "      <th>2477.700694</th>\n",
              "      <th>2480.15873</th>\n",
              "      <th>2482.621648</th>\n",
              "      <th>2485.089463</th>\n",
              "      <th>2487.562189</th>\n",
              "      <th>2490.039841</th>\n",
              "      <th>2492.522433</th>\n",
              "      <th>2495.00998</th>\n",
              "      <th>2497.502498</th>\n",
              "      <th>2500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0.098681</td>\n",
              "      <td>0.100515</td>\n",
              "      <td>0.102056</td>\n",
              "      <td>0.100267</td>\n",
              "      <td>0.096954</td>\n",
              "      <td>0.096161</td>\n",
              "      <td>0.097151</td>\n",
              "      <td>0.096790</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968741</td>\n",
              "      <td>2.968988</td>\n",
              "      <td>2.958685</td>\n",
              "      <td>2.950201</td>\n",
              "      <td>2.950122</td>\n",
              "      <td>2.948725</td>\n",
              "      <td>2.939113</td>\n",
              "      <td>2.929406</td>\n",
              "      <td>2.929555</td>\n",
              "      <td>2.927579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0.098081</td>\n",
              "      <td>0.099926</td>\n",
              "      <td>0.101394</td>\n",
              "      <td>0.099664</td>\n",
              "      <td>0.096598</td>\n",
              "      <td>0.095915</td>\n",
              "      <td>0.096567</td>\n",
              "      <td>0.095609</td>\n",
              "      <td>...</td>\n",
              "      <td>2.960005</td>\n",
              "      <td>2.959948</td>\n",
              "      <td>2.951504</td>\n",
              "      <td>2.945633</td>\n",
              "      <td>2.947553</td>\n",
              "      <td>2.947326</td>\n",
              "      <td>2.937901</td>\n",
              "      <td>2.926926</td>\n",
              "      <td>2.924102</td>\n",
              "      <td>2.920722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>24.00</td>\n",
              "      <td>0.089885</td>\n",
              "      <td>0.092072</td>\n",
              "      <td>0.094055</td>\n",
              "      <td>0.092618</td>\n",
              "      <td>0.089560</td>\n",
              "      <td>0.088900</td>\n",
              "      <td>0.089790</td>\n",
              "      <td>0.089088</td>\n",
              "      <td>...</td>\n",
              "      <td>2.943931</td>\n",
              "      <td>2.943679</td>\n",
              "      <td>2.930295</td>\n",
              "      <td>2.919846</td>\n",
              "      <td>2.920668</td>\n",
              "      <td>2.922776</td>\n",
              "      <td>2.913596</td>\n",
              "      <td>2.904503</td>\n",
              "      <td>2.903535</td>\n",
              "      <td>2.901086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>23.60</td>\n",
              "      <td>0.088701</td>\n",
              "      <td>0.090287</td>\n",
              "      <td>0.091825</td>\n",
              "      <td>0.090534</td>\n",
              "      <td>0.087883</td>\n",
              "      <td>0.087348</td>\n",
              "      <td>0.088151</td>\n",
              "      <td>0.087593</td>\n",
              "      <td>...</td>\n",
              "      <td>2.935452</td>\n",
              "      <td>2.938259</td>\n",
              "      <td>2.928736</td>\n",
              "      <td>2.921757</td>\n",
              "      <td>2.924166</td>\n",
              "      <td>2.924666</td>\n",
              "      <td>2.914831</td>\n",
              "      <td>2.905151</td>\n",
              "      <td>2.902643</td>\n",
              "      <td>2.897351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>23.60</td>\n",
              "      <td>0.095273</td>\n",
              "      <td>0.096945</td>\n",
              "      <td>0.098684</td>\n",
              "      <td>0.097460</td>\n",
              "      <td>0.094674</td>\n",
              "      <td>0.093949</td>\n",
              "      <td>0.094563</td>\n",
              "      <td>0.093743</td>\n",
              "      <td>...</td>\n",
              "      <td>2.966199</td>\n",
              "      <td>2.968021</td>\n",
              "      <td>2.955198</td>\n",
              "      <td>2.942411</td>\n",
              "      <td>2.943006</td>\n",
              "      <td>2.942151</td>\n",
              "      <td>2.931640</td>\n",
              "      <td>2.918549</td>\n",
              "      <td>2.918717</td>\n",
              "      <td>2.917849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>True</td>\n",
              "      <td>25.52</td>\n",
              "      <td>0.076506</td>\n",
              "      <td>0.075591</td>\n",
              "      <td>0.074629</td>\n",
              "      <td>0.072980</td>\n",
              "      <td>0.072275</td>\n",
              "      <td>0.072979</td>\n",
              "      <td>0.072688</td>\n",
              "      <td>0.070171</td>\n",
              "      <td>...</td>\n",
              "      <td>2.962918</td>\n",
              "      <td>2.970997</td>\n",
              "      <td>2.967865</td>\n",
              "      <td>2.957785</td>\n",
              "      <td>2.952054</td>\n",
              "      <td>2.949278</td>\n",
              "      <td>2.941087</td>\n",
              "      <td>2.935639</td>\n",
              "      <td>2.936698</td>\n",
              "      <td>2.938116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>True</td>\n",
              "      <td>25.52</td>\n",
              "      <td>0.071916</td>\n",
              "      <td>0.071201</td>\n",
              "      <td>0.070450</td>\n",
              "      <td>0.068871</td>\n",
              "      <td>0.068104</td>\n",
              "      <td>0.068746</td>\n",
              "      <td>0.068455</td>\n",
              "      <td>0.065891</td>\n",
              "      <td>...</td>\n",
              "      <td>2.982798</td>\n",
              "      <td>2.982529</td>\n",
              "      <td>2.968697</td>\n",
              "      <td>2.958179</td>\n",
              "      <td>2.962882</td>\n",
              "      <td>2.967330</td>\n",
              "      <td>2.958188</td>\n",
              "      <td>2.948901</td>\n",
              "      <td>2.948394</td>\n",
              "      <td>2.943151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2036</th>\n",
              "      <td>True</td>\n",
              "      <td>25.37</td>\n",
              "      <td>0.055557</td>\n",
              "      <td>0.054680</td>\n",
              "      <td>0.053789</td>\n",
              "      <td>0.052091</td>\n",
              "      <td>0.051338</td>\n",
              "      <td>0.052176</td>\n",
              "      <td>0.052068</td>\n",
              "      <td>0.049510</td>\n",
              "      <td>...</td>\n",
              "      <td>2.960384</td>\n",
              "      <td>2.958313</td>\n",
              "      <td>2.946722</td>\n",
              "      <td>2.938467</td>\n",
              "      <td>2.936874</td>\n",
              "      <td>2.936340</td>\n",
              "      <td>2.925951</td>\n",
              "      <td>2.920350</td>\n",
              "      <td>2.921682</td>\n",
              "      <td>2.917657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2037</th>\n",
              "      <td>True</td>\n",
              "      <td>25.37</td>\n",
              "      <td>0.050590</td>\n",
              "      <td>0.049846</td>\n",
              "      <td>0.049057</td>\n",
              "      <td>0.047327</td>\n",
              "      <td>0.046489</td>\n",
              "      <td>0.047292</td>\n",
              "      <td>0.047258</td>\n",
              "      <td>0.044905</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968252</td>\n",
              "      <td>2.967836</td>\n",
              "      <td>2.953877</td>\n",
              "      <td>2.942397</td>\n",
              "      <td>2.945923</td>\n",
              "      <td>2.948910</td>\n",
              "      <td>2.940729</td>\n",
              "      <td>2.926084</td>\n",
              "      <td>2.923839</td>\n",
              "      <td>2.919868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2038</th>\n",
              "      <td>True</td>\n",
              "      <td>25.37</td>\n",
              "      <td>0.063837</td>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.062142</td>\n",
              "      <td>0.060671</td>\n",
              "      <td>0.060073</td>\n",
              "      <td>0.060987</td>\n",
              "      <td>0.060884</td>\n",
              "      <td>0.058203</td>\n",
              "      <td>...</td>\n",
              "      <td>2.981493</td>\n",
              "      <td>2.981399</td>\n",
              "      <td>2.970350</td>\n",
              "      <td>2.962294</td>\n",
              "      <td>2.963960</td>\n",
              "      <td>2.962348</td>\n",
              "      <td>2.953168</td>\n",
              "      <td>2.948091</td>\n",
              "      <td>2.949026</td>\n",
              "      <td>2.943110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1823 rows × 1781 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72d5a398-0dca-4075-a73b-7e60d12c16f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72d5a398-0dca-4075-a73b-7e60d12c16f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72d5a398-0dca-4075-a73b-7e60d12c16f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1,y1=data_a3.shape\n",
        "data_a1=data_a3.iloc[0::,2:yy+1]\n",
        "data_a1"
      ],
      "metadata": {
        "id": "9VdA_HdZsSli",
        "outputId": "a9e8283f-d312-44fb-c072-ba516cb065a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      899.9280058  900.2520706  900.5763689  900.9009009  901.2256669  \\\n",
              "0        0.098681     0.100515     0.102056     0.100267     0.096954   \n",
              "1        0.098081     0.099926     0.101394     0.099664     0.096598   \n",
              "2        0.089885     0.092072     0.094055     0.092618     0.089560   \n",
              "3        0.088701     0.090287     0.091825     0.090534     0.087883   \n",
              "4        0.095273     0.096945     0.098684     0.097460     0.094674   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "2034     0.076506     0.075591     0.074629     0.072980     0.072275   \n",
              "2035     0.071916     0.071201     0.070450     0.068871     0.068104   \n",
              "2036     0.055557     0.054680     0.053789     0.052091     0.051338   \n",
              "2037     0.050590     0.049846     0.049057     0.047327     0.046489   \n",
              "2038     0.063837     0.062890     0.062142     0.060671     0.060073   \n",
              "\n",
              "      901.5506671  901.8759019  902.2013713  902.5270758  902.8530155  ...  \\\n",
              "0        0.096161     0.097151     0.096790     0.095622     0.095521  ...   \n",
              "1        0.095915     0.096567     0.095609     0.094073     0.093994  ...   \n",
              "2        0.088900     0.089790     0.089088     0.087585     0.087353  ...   \n",
              "3        0.087348     0.088151     0.087593     0.086458     0.086425  ...   \n",
              "4        0.093949     0.094563     0.093743     0.092318     0.092116  ...   \n",
              "...           ...          ...          ...          ...          ...  ...   \n",
              "2034     0.072979     0.072688     0.070171     0.068566     0.069321  ...   \n",
              "2035     0.068746     0.068455     0.065891     0.064076     0.064532  ...   \n",
              "2036     0.052176     0.052068     0.049510     0.047720     0.048518  ...   \n",
              "2037     0.047292     0.047258     0.044905     0.043365     0.044220  ...   \n",
              "2038     0.060987     0.060884     0.058203     0.056162     0.056647  ...   \n",
              "\n",
              "      2477.700694  2480.15873  2482.621648  2485.089463  2487.562189  \\\n",
              "0        2.968741    2.968988     2.958685     2.950201     2.950122   \n",
              "1        2.960005    2.959948     2.951504     2.945633     2.947553   \n",
              "2        2.943931    2.943679     2.930295     2.919846     2.920668   \n",
              "3        2.935452    2.938259     2.928736     2.921757     2.924166   \n",
              "4        2.966199    2.968021     2.955198     2.942411     2.943006   \n",
              "...           ...         ...          ...          ...          ...   \n",
              "2034     2.962918    2.970997     2.967865     2.957785     2.952054   \n",
              "2035     2.982798    2.982529     2.968697     2.958179     2.962882   \n",
              "2036     2.960384    2.958313     2.946722     2.938467     2.936874   \n",
              "2037     2.968252    2.967836     2.953877     2.942397     2.945923   \n",
              "2038     2.981493    2.981399     2.970350     2.962294     2.963960   \n",
              "\n",
              "      2490.039841  2492.522433  2495.00998  2497.502498      2500  \n",
              "0        2.948725     2.939113    2.929406     2.929555  2.927579  \n",
              "1        2.947326     2.937901    2.926926     2.924102  2.920722  \n",
              "2        2.922776     2.913596    2.904503     2.903535  2.901086  \n",
              "3        2.924666     2.914831    2.905151     2.902643  2.897351  \n",
              "4        2.942151     2.931640    2.918549     2.918717  2.917849  \n",
              "...           ...          ...         ...          ...       ...  \n",
              "2034     2.949278     2.941087    2.935639     2.936698  2.938116  \n",
              "2035     2.967330     2.958188    2.948901     2.948394  2.943151  \n",
              "2036     2.936340     2.925951    2.920350     2.921682  2.917657  \n",
              "2037     2.948910     2.940729    2.926084     2.923839  2.919868  \n",
              "2038     2.962348     2.953168    2.948091     2.949026  2.943110  \n",
              "\n",
              "[1823 rows x 1779 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-939e7c3b-8651-4400-80bd-4c536f9acf99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>899.9280058</th>\n",
              "      <th>900.2520706</th>\n",
              "      <th>900.5763689</th>\n",
              "      <th>900.9009009</th>\n",
              "      <th>901.2256669</th>\n",
              "      <th>901.5506671</th>\n",
              "      <th>901.8759019</th>\n",
              "      <th>902.2013713</th>\n",
              "      <th>902.5270758</th>\n",
              "      <th>902.8530155</th>\n",
              "      <th>...</th>\n",
              "      <th>2477.700694</th>\n",
              "      <th>2480.15873</th>\n",
              "      <th>2482.621648</th>\n",
              "      <th>2485.089463</th>\n",
              "      <th>2487.562189</th>\n",
              "      <th>2490.039841</th>\n",
              "      <th>2492.522433</th>\n",
              "      <th>2495.00998</th>\n",
              "      <th>2497.502498</th>\n",
              "      <th>2500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.098681</td>\n",
              "      <td>0.100515</td>\n",
              "      <td>0.102056</td>\n",
              "      <td>0.100267</td>\n",
              "      <td>0.096954</td>\n",
              "      <td>0.096161</td>\n",
              "      <td>0.097151</td>\n",
              "      <td>0.096790</td>\n",
              "      <td>0.095622</td>\n",
              "      <td>0.095521</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968741</td>\n",
              "      <td>2.968988</td>\n",
              "      <td>2.958685</td>\n",
              "      <td>2.950201</td>\n",
              "      <td>2.950122</td>\n",
              "      <td>2.948725</td>\n",
              "      <td>2.939113</td>\n",
              "      <td>2.929406</td>\n",
              "      <td>2.929555</td>\n",
              "      <td>2.927579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.098081</td>\n",
              "      <td>0.099926</td>\n",
              "      <td>0.101394</td>\n",
              "      <td>0.099664</td>\n",
              "      <td>0.096598</td>\n",
              "      <td>0.095915</td>\n",
              "      <td>0.096567</td>\n",
              "      <td>0.095609</td>\n",
              "      <td>0.094073</td>\n",
              "      <td>0.093994</td>\n",
              "      <td>...</td>\n",
              "      <td>2.960005</td>\n",
              "      <td>2.959948</td>\n",
              "      <td>2.951504</td>\n",
              "      <td>2.945633</td>\n",
              "      <td>2.947553</td>\n",
              "      <td>2.947326</td>\n",
              "      <td>2.937901</td>\n",
              "      <td>2.926926</td>\n",
              "      <td>2.924102</td>\n",
              "      <td>2.920722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.089885</td>\n",
              "      <td>0.092072</td>\n",
              "      <td>0.094055</td>\n",
              "      <td>0.092618</td>\n",
              "      <td>0.089560</td>\n",
              "      <td>0.088900</td>\n",
              "      <td>0.089790</td>\n",
              "      <td>0.089088</td>\n",
              "      <td>0.087585</td>\n",
              "      <td>0.087353</td>\n",
              "      <td>...</td>\n",
              "      <td>2.943931</td>\n",
              "      <td>2.943679</td>\n",
              "      <td>2.930295</td>\n",
              "      <td>2.919846</td>\n",
              "      <td>2.920668</td>\n",
              "      <td>2.922776</td>\n",
              "      <td>2.913596</td>\n",
              "      <td>2.904503</td>\n",
              "      <td>2.903535</td>\n",
              "      <td>2.901086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.088701</td>\n",
              "      <td>0.090287</td>\n",
              "      <td>0.091825</td>\n",
              "      <td>0.090534</td>\n",
              "      <td>0.087883</td>\n",
              "      <td>0.087348</td>\n",
              "      <td>0.088151</td>\n",
              "      <td>0.087593</td>\n",
              "      <td>0.086458</td>\n",
              "      <td>0.086425</td>\n",
              "      <td>...</td>\n",
              "      <td>2.935452</td>\n",
              "      <td>2.938259</td>\n",
              "      <td>2.928736</td>\n",
              "      <td>2.921757</td>\n",
              "      <td>2.924166</td>\n",
              "      <td>2.924666</td>\n",
              "      <td>2.914831</td>\n",
              "      <td>2.905151</td>\n",
              "      <td>2.902643</td>\n",
              "      <td>2.897351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.095273</td>\n",
              "      <td>0.096945</td>\n",
              "      <td>0.098684</td>\n",
              "      <td>0.097460</td>\n",
              "      <td>0.094674</td>\n",
              "      <td>0.093949</td>\n",
              "      <td>0.094563</td>\n",
              "      <td>0.093743</td>\n",
              "      <td>0.092318</td>\n",
              "      <td>0.092116</td>\n",
              "      <td>...</td>\n",
              "      <td>2.966199</td>\n",
              "      <td>2.968021</td>\n",
              "      <td>2.955198</td>\n",
              "      <td>2.942411</td>\n",
              "      <td>2.943006</td>\n",
              "      <td>2.942151</td>\n",
              "      <td>2.931640</td>\n",
              "      <td>2.918549</td>\n",
              "      <td>2.918717</td>\n",
              "      <td>2.917849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>0.076506</td>\n",
              "      <td>0.075591</td>\n",
              "      <td>0.074629</td>\n",
              "      <td>0.072980</td>\n",
              "      <td>0.072275</td>\n",
              "      <td>0.072979</td>\n",
              "      <td>0.072688</td>\n",
              "      <td>0.070171</td>\n",
              "      <td>0.068566</td>\n",
              "      <td>0.069321</td>\n",
              "      <td>...</td>\n",
              "      <td>2.962918</td>\n",
              "      <td>2.970997</td>\n",
              "      <td>2.967865</td>\n",
              "      <td>2.957785</td>\n",
              "      <td>2.952054</td>\n",
              "      <td>2.949278</td>\n",
              "      <td>2.941087</td>\n",
              "      <td>2.935639</td>\n",
              "      <td>2.936698</td>\n",
              "      <td>2.938116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>0.071916</td>\n",
              "      <td>0.071201</td>\n",
              "      <td>0.070450</td>\n",
              "      <td>0.068871</td>\n",
              "      <td>0.068104</td>\n",
              "      <td>0.068746</td>\n",
              "      <td>0.068455</td>\n",
              "      <td>0.065891</td>\n",
              "      <td>0.064076</td>\n",
              "      <td>0.064532</td>\n",
              "      <td>...</td>\n",
              "      <td>2.982798</td>\n",
              "      <td>2.982529</td>\n",
              "      <td>2.968697</td>\n",
              "      <td>2.958179</td>\n",
              "      <td>2.962882</td>\n",
              "      <td>2.967330</td>\n",
              "      <td>2.958188</td>\n",
              "      <td>2.948901</td>\n",
              "      <td>2.948394</td>\n",
              "      <td>2.943151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2036</th>\n",
              "      <td>0.055557</td>\n",
              "      <td>0.054680</td>\n",
              "      <td>0.053789</td>\n",
              "      <td>0.052091</td>\n",
              "      <td>0.051338</td>\n",
              "      <td>0.052176</td>\n",
              "      <td>0.052068</td>\n",
              "      <td>0.049510</td>\n",
              "      <td>0.047720</td>\n",
              "      <td>0.048518</td>\n",
              "      <td>...</td>\n",
              "      <td>2.960384</td>\n",
              "      <td>2.958313</td>\n",
              "      <td>2.946722</td>\n",
              "      <td>2.938467</td>\n",
              "      <td>2.936874</td>\n",
              "      <td>2.936340</td>\n",
              "      <td>2.925951</td>\n",
              "      <td>2.920350</td>\n",
              "      <td>2.921682</td>\n",
              "      <td>2.917657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2037</th>\n",
              "      <td>0.050590</td>\n",
              "      <td>0.049846</td>\n",
              "      <td>0.049057</td>\n",
              "      <td>0.047327</td>\n",
              "      <td>0.046489</td>\n",
              "      <td>0.047292</td>\n",
              "      <td>0.047258</td>\n",
              "      <td>0.044905</td>\n",
              "      <td>0.043365</td>\n",
              "      <td>0.044220</td>\n",
              "      <td>...</td>\n",
              "      <td>2.968252</td>\n",
              "      <td>2.967836</td>\n",
              "      <td>2.953877</td>\n",
              "      <td>2.942397</td>\n",
              "      <td>2.945923</td>\n",
              "      <td>2.948910</td>\n",
              "      <td>2.940729</td>\n",
              "      <td>2.926084</td>\n",
              "      <td>2.923839</td>\n",
              "      <td>2.919868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2038</th>\n",
              "      <td>0.063837</td>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.062142</td>\n",
              "      <td>0.060671</td>\n",
              "      <td>0.060073</td>\n",
              "      <td>0.060987</td>\n",
              "      <td>0.060884</td>\n",
              "      <td>0.058203</td>\n",
              "      <td>0.056162</td>\n",
              "      <td>0.056647</td>\n",
              "      <td>...</td>\n",
              "      <td>2.981493</td>\n",
              "      <td>2.981399</td>\n",
              "      <td>2.970350</td>\n",
              "      <td>2.962294</td>\n",
              "      <td>2.963960</td>\n",
              "      <td>2.962348</td>\n",
              "      <td>2.953168</td>\n",
              "      <td>2.948091</td>\n",
              "      <td>2.949026</td>\n",
              "      <td>2.943110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1823 rows × 1779 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-939e7c3b-8651-4400-80bd-4c536f9acf99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-939e7c3b-8651-4400-80bd-4c536f9acf99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-939e7c3b-8651-4400-80bd-4c536f9acf99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preperation\n",
        "df=pd.DataFrame({\n",
        "    'bool':['true','false','true','false'],\n",
        "    'int':[1,2,3,4]\n",
        "})\n",
        "df2=df\n",
        "df.iloc[0,0]\n",
        "df"
      ],
      "metadata": {
        "id": "cwNpqFozeoZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range(4)"
      ],
      "metadata": {
        "id": "jzMaWgomhKV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai=[]\n",
        "for i in range(4):\n",
        "    if df.iloc[i,0]=='false':\n",
        "        ai.append(i)\n",
        "df2=df.drop(ai,axis=0) #\n",
        "df2"
      ],
      "metadata": {
        "id": "8B2RFUcqdAop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_a1_n=data_a1.to_numpy()\n",
        "data_a1_input=data_a1_n\n",
        "data_a1_input"
      ],
      "metadata": {
        "id": "V_jf7CQ6yb9k",
        "outputId": "5c3b4154-a235-4356-b63a-e09dd01b4755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09868074, 0.1005148 , 0.10205633, ..., 2.92940605, 2.9295551 ,\n",
              "        2.92757921],\n",
              "       [0.0980814 , 0.09992567, 0.10139396, ..., 2.92692573, 2.92410227,\n",
              "        2.92072185],\n",
              "       [0.08988517, 0.09207206, 0.0940546 , ..., 2.90450321, 2.90353459,\n",
              "        2.90108571],\n",
              "       ...,\n",
              "       [0.05555697, 0.05468017, 0.05378911, ..., 2.92035018, 2.92168167,\n",
              "        2.917657  ],\n",
              "       [0.05058956, 0.0498458 , 0.04905745, ..., 2.92608398, 2.92383935,\n",
              "        2.91986778],\n",
              "       [0.06383698, 0.06289033, 0.06214161, ..., 2.94809062, 2.94902612,\n",
              "        2.9431105 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a1_output=data_a3.iloc[0::,1:2]\n",
        "data_a1_output.head()"
      ],
      "metadata": {
        "id": "BLFRIBkgz3CZ",
        "outputId": "30d6c3d3-5e20-4de5-af70-ed9e4253c572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Y_A\n",
              "0  24.0\n",
              "1  24.0\n",
              "2  24.0\n",
              "3  23.6\n",
              "4  23.6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a261ab7-c6ee-4f31-8888-37e894497788\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a261ab7-c6ee-4f31-8888-37e894497788')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a261ab7-c6ee-4f31-8888-37e894497788 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a261ab7-c6ee-4f31-8888-37e894497788');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a1_output_n=data_a1_output.to_numpy().flatten()\n",
        "data_a1_target=data_a1_output_n\n",
        "data_a1_target"
      ],
      "metadata": {
        "id": "zoNeiduI0A39",
        "outputId": "0ca6aaec-1cde-4493-dde9-4f6bc0174871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.  , 24.  , 24.  , ..., 25.37, 25.37, 25.37])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, recall_score, precision_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.font_manager as fm "
      ],
      "metadata": {
        "id": "bVeSGhcR2SXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_a1_input"
      ],
      "metadata": {
        "id": "p9V_yZ8kPtOs",
        "outputId": "5918a5e1-2d8c-4691-eb23-b67db59f9ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09868074, 0.1005148 , 0.10205633, ..., 2.92940605, 2.9295551 ,\n",
              "        2.92757921],\n",
              "       [0.0980814 , 0.09992567, 0.10139396, ..., 2.92692573, 2.92410227,\n",
              "        2.92072185],\n",
              "       [0.08988517, 0.09207206, 0.0940546 , ..., 2.90450321, 2.90353459,\n",
              "        2.90108571],\n",
              "       ...,\n",
              "       [0.05555697, 0.05468017, 0.05378911, ..., 2.92035018, 2.92168167,\n",
              "        2.917657  ],\n",
              "       [0.05058956, 0.0498458 , 0.04905745, ..., 2.92608398, 2.92383935,\n",
              "        2.91986778],\n",
              "       [0.06383698, 0.06289033, 0.06214161, ..., 2.94809062, 2.94902612,\n",
              "        2.9431105 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a1_target"
      ],
      "metadata": {
        "id": "2Nht4PFTPxO2",
        "outputId": "42ee8f75-f99c-4e86-c877-236ce99a211a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.  , 24.  , 24.  , ..., 25.37, 25.37, 25.37])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Y6ZEMqfXP1sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "feXyLYlmP6vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "vLocwQSOP-Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= make_pipeline(\n",
        "    StandardScaler(),\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "#bagging_model=BaggingRegressor(base_model, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
        "bagging_model=BaggingRegressor(base_model, n_estimators=10, max_samples=1, max_features=1)"
      ],
      "metadata": {
        "id": "oPdbAxKaQBwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=base_model,\n",
        "#    X=boston.data, y=boston.target,\n",
        "#    X=raman, y=raman_target,\n",
        "     X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "EnnbLCE7QG73",
        "outputId": "a25c6886-583f-467f-cae9-c83661b15b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 0.045820188522338864 (+/-0.0015844369345036004)\n",
            "avg score time: 0.0685882568359375 (+/- 0.0034261888532887974)\n",
            "avg test score: -1.4419025215900863 (+/- 0.6318436938149143)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=bagging_model,\n",
        "#   X=raman, y=raman_target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "3W-RemVpQg2l",
        "outputId": "c4189236-bd37-4716-b449-a49a24e3a0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 0.02366957664489746 (+/-0.003129542901781206)\n",
            "avg score time: 0.0010915756225585937 (+/- 0.0007816880935425778)\n",
            "avg test score: nan (+/- nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= make_pipeline(\n",
        "    StandardScaler(),\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "bagging_model=BaggingRegressor(base_model, n_estimators=10, max_samples=1, max_features=1)"
      ],
      "metadata": {
        "id": "PwNjC934Q2Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=bagging_model,\n",
        "#   X=raman, y=raman_target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "84IDQP5RQ30b",
        "outputId": "a88ef12f-28ea-4984-ad0b-65959d806f1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 0.02416958808898926 (+/-0.0028658162677650196)\n",
            "avg score time: 0.000666666030883789 (+/- 5.8494413195786545e-05)\n",
            "avg test score: nan (+/- nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "lbCVOEQ8RO4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVR()\n",
        ")"
      ],
      "metadata": {
        "id": "aMppnD9jRK36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=base_model,\n",
        "#   X=raman, y=raman_target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "SVo17h8VRUnL",
        "outputId": "53d0855a-1956-44d8-d717-4fde80ea980c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 1.2718009948730469 (+/-0.03652763700187674)\n",
            "avg score time: 0.5947352409362793 (+/- 0.09062761796551676)\n",
            "avg test score: -0.9165702147180393 (+/- 0.4658393073533814)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=bagging_model,\n",
        "#   X=raman, y=raman_target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "AR0Sls0zRfk6",
        "outputId": "811153a3-a334-40a5-d1b1-5f564c5f46ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 0.02372879981994629 (+/-0.0029020430670869575)\n",
            "avg score time: 0.0007717132568359375 (+/- 6.118982060635792e-05)\n",
            "avg test score: nan (+/- nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_scorer.py\", line 418, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 705, in score\n",
            "    y_pred = self.predict(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 1129, in predict\n",
            "    all_y_hat = Parallel(n_jobs=n_jobs, verbose=self.verbose)(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 196, in _parallel_predict_regression\n",
            "    return sum(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_bagging.py\", line 197, in <genexpr>\n",
            "    estimator.predict(X[:, features])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
            "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 470, in predict\n",
            "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_regression.py\", line 229, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_base.py\", line 727, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 1, n_neighbors = 5\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "Jan6opIrR6CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= make_pipeline(\n",
        "    StandardScaler(),\n",
        "    DecisionTreeRegressor()\n",
        ")\n",
        "\n",
        "bagging_model=BaggingRegressor(base_model, n_estimators=10, max_samples=0.5, max_features=0.5)"
      ],
      "metadata": {
        "id": "Y1SLPHWYRxmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=base_model,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "zhbBOtvZSBc2",
        "outputId": "5c2bd786-d1a3-449d-ca4a-9d5319a15330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 2.6703796863555906 (+/-0.920426204008081)\n",
            "avg score time: 0.005116891860961914 (+/- 0.0003251150227726041)\n",
            "avg test score: -1.8212000068182632 (+/- 0.5811561372608995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=bagging_model,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "QlJ6pcw_SOrR",
        "outputId": "db1e1026-f6fb-4689-a071-28ca58f9f4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 4.572564554214478 (+/-0.5080498456882404)\n",
            "avg score time: 0.0305997371673584 (+/- 0.00032107859701645855)\n",
            "avg test score: -1.2071364465231909 (+/- 0.6944107596180656)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forests of randomized trees"
      ],
      "metadata": {
        "id": "cJhoG55ASpgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1)Random Forest\n",
        "##2) Extra-tree"
      ],
      "metadata": {
        "id": "UMcLq4JtSvcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor"
      ],
      "metadata": {
        "id": "47nwrBvZSfNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestRegressor()\n",
        ")"
      ],
      "metadata": {
        "id": "3VgZUOZ_XA7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=model,\n",
        "    #X=boston.data, y=boston.target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "zqvjTNJgXJrN",
        "outputId": "b7d93421-1aca-49c4-94ae-40f6c940f164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 126.4928403377533 (+/-9.623167307134485)\n",
            "avg score time: 0.020734024047851563 (+/- 0.0018296590927983736)\n",
            "avg test score: -0.9897800387582553 (+/- 0.5343143224253185)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXtremely Randomized Trees"
      ],
      "metadata": {
        "id": "RdjIijKVYHYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =make_pipeline(\n",
        "    StandardScaler(),\n",
        "    ExtraTreesRegressor()\n",
        ")"
      ],
      "metadata": {
        "id": "Ybf1LDxWYLrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=model,\n",
        "    #X=boston.data, y=boston.target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "KePzz2SYYPCt",
        "outputId": "c59275b4-2565-40e5-a349-2f92c53c5570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 38.80483794212341 (+/-2.5960222498418943)\n",
            "avg score time: 0.020905208587646485 (+/- 0.0016642307223451503)\n",
            "avg test score: -1.100858485618148 (+/- 0.5192900622514408)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost"
      ],
      "metadata": {
        "id": "yta-oLBBY7wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor"
      ],
      "metadata": {
        "id": "jTbMMO3sZG6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    AdaBoostRegressor()\n",
        ")"
      ],
      "metadata": {
        "id": "a9WoZhPFY9il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=model,\n",
        "    #X=boston.data, y=boston.target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=10)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))\n",
        "cross_val['test_score']"
      ],
      "metadata": {
        "id": "ODySNfEhZPtN",
        "outputId": "87aba53a-2e61-416c-be59-74f51f9019df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 21.0720064163208 (+/-0.5881480215706448)\n",
            "avg score time: 0.030605673789978027 (+/- 0.0011593899956921264)\n",
            "avg test score: -0.7580925581625175 (+/- 0.5224523036543586)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.14601707, -1.00763221, -0.3468731 , -0.70932487, -0.52510098,\n",
              "       -0.15535816, -0.68780486, -0.59914464, -0.46165638, -0.94201332])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=model,\n",
        "    #X=boston.data, y=boston.target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=5)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))"
      ],
      "metadata": {
        "id": "y7Q7EUEYZTz6",
        "outputId": "9aa6ec0c-30fa-4b2a-cbca-1143e397c92d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 18.05485577583313 (+/-0.48392065170040377)\n",
            "avg score time: 0.05358576774597168 (+/- 0.0012743199035938674)\n",
            "avg test score: -0.9392283789188914 (+/- 0.7698633597497156)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Tree boosting"
      ],
      "metadata": {
        "id": "lDfA_k0eaF4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "5CqYtnYTZCzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    GradientBoostingRegressor()\n",
        ")"
      ],
      "metadata": {
        "id": "StVC-DclaM84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=model,\n",
        "    #X=boston.data, y=boston.target,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=10)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/- {})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/- {})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))\n",
        "cross_val['test_score']"
      ],
      "metadata": {
        "id": "jr2azuNNaca6",
        "outputId": "6fda00ae-5e08-46a9-c13c-17404adde1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 68.75200200080872 (+/-0.610956789046703)\n",
            "avg score time: 0.003492307662963867 (+/- 5.532244077452334e-05)\n",
            "avg test score: -0.6875897940572046 (+/- 0.4174246111352803)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4303515 , -0.22563045, -0.59361052, -1.20796337, -0.37889559,\n",
              "       -0.57134849, -1.14557941, -0.29868318, -0.22366214, -0.80017329])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressor vote"
      ],
      "metadata": {
        "id": "hEzKwi3_cjqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "8Ck74P5mcsAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=LinearRegression()\n",
        "model2=GradientBoostingRegressor()\n",
        "model3=RandomForestRegressor()\n",
        "vote_model =VotingRegressor(estimators=[('linear',model1),('gbr',model2),('rfr',model3)],\n",
        "                              weights=[1,1,1])"
      ],
      "metadata": {
        "id": "Y3aKM1QGcxCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [model1,model2,model3,vote_model]:\n",
        "    model_name=str(type(model)).split('.')[-1][:-2]\n",
        "    scores=cross_val_score(model,data_a1_input,data_a1_target,cv=20)\n",
        "    print('R2: %0.2f (+/- %0.2f) [%s]' % ( scores.mean(), scores.std(), model_name))"
      ],
      "metadata": {
        "id": "nTHN_bp9cyvm",
        "outputId": "0e60bf81-064c-4aac-8be8-d63a29e28d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2: -3086.72 (+/- 13321.88) [LinearRegression]\n",
            "R2: -1.84 (+/- 2.50) [GradientBoostingRegressor]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e0c1db428bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvote_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_a1_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_a1_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R2: %0.2f (+/- %0.2f) [%s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hS5I6o8Tcqxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "스택회귀"
      ],
      "metadata": {
        "id": "hoflYauXv0yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import StackingRegressor"
      ],
      "metadata": {
        "id": "rDPsyuQkcjNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators=[('ridge',Ridge()),\n",
        "            ('lasso',Lasso()),\n",
        "            ('svr',SVR())]"
      ],
      "metadata": {
        "id": "jh_l1Z2lv7AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    StackingRegressor(\n",
        "        estimators=estimators,\n",
        "        final_estimator=GradientBoostingRegressor()\n",
        ")\n",
        ")"
      ],
      "metadata": {
        "id": "MIRDvY34v-m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val=cross_validate(\n",
        "    estimator=reg,\n",
        "    X=data_a1_input, y=data_a1_target,\n",
        "    cv=10)\n",
        "print('avg fit time: {} (+/-{})'.format(cross_val['fit_time'].mean(), cross_val['fit_time'].std()))\n",
        "print('avg score time: {} (+/-{})'.format(cross_val['score_time'].mean(), cross_val['score_time'].std()))\n",
        "print('avg test score: {} (+/-{})'.format(cross_val['test_score'].mean(), cross_val['test_score'].std()))\n",
        "cross_val['test_score']"
      ],
      "metadata": {
        "id": "xz7Q4Ra-w3Je",
        "outputId": "1fe75cfe-080f-466d-c55c-8eaff4ab5b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg fit time: 11.186891531944275 (+/-0.3388646858065281)\n",
            "avg score time: 0.3847131013870239 (+/-0.0783690524610559)\n",
            "avg test score: -0.44060417354618087 (+/-1.3513189059998405)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.23897677,  0.41236719,  0.30956051, -4.22360059, -1.12012059,\n",
              "        0.44538645,  0.41049559,  0.3485722 , -0.28522689, -0.46449884])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ar28dkfAwCkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}